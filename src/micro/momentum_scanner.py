import sqlite3
import pandas as pd
import os
import sys
import json
from datetime import datetime
from collections import Counter
from scipy import stats
import numpy as np

# è·¯å¾„è‡ªé€‚åº”
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
data_dir = os.path.join(project_root, 'data')

class MomentumRanker:
    def __init__(self):
        self.config = self._load_config()

    def _load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤å€¼"""
        config_path = os.path.join(project_root, 'models_config.json')
        default_config = {
            "us_blacklist": ["SQQQ", "TQQQ", "SOXL", "SOXS", "SPXU", "SPXS", "SDS", "SSO", "UPRO", "QID", "QLD", "TNA", "TZA", "UVXY", "VIXY", "SVXY", "LABU", "LABD", "YANG", "YINN", "FNGU", "FNGD", "WEBL", "WEBS", "KOLD", "BOIL", "TSLY", "NVDY", "AMDY", "MSTY", "CONY", "APLY", "GOOY", "MSFY", "AMZY", "FBY", "OARK", "XOMO", "JPMO", "DISO", "NFLY", "SQY", "PYPY", "AIYY", "YMAX", "YMAG", "ULTY", "SVOL", "TLTW", "HYGW", "LQDW", "BITX"],
            "min_volume_cn": 200000000,
            "min_volume_us": 20000000,
            "max_change_pct": 400,
            "rsrs_window": 18
        }
        
        if os.path.exists(config_path):
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    # åˆå¹¶/è¦†ç›–é»˜è®¤é…ç½®ï¼Œé˜²æ­¢ key ç¼ºå¤±æŠ¥é”™
                    if "scanner_filters" in data:
                        return data["scanner_filters"]
                    else:
                        print("âš ï¸ é…ç½®æ–‡ä»¶ä¸­æœªæ‰¾åˆ° scanner_filtersï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            except Exception as e:
                print(f"âš ï¸ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}, ä½¿ç”¨é»˜è®¤é…ç½®")
        else:
            print("âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        
        return default_config

    def calculate_rsrs(self, series, window=18):
        """
        è®¡ç®—è¶‹åŠ¿å¼ºåº¦ (RSRS æ›¿ä»£æŒ‡æ ‡)
        è¿”å›: -1.0 ~ 1.0 (R2 * Sign(Slope))
        """
        try:
            if len(series) < window:
                return 0.0
            
            # å–æœ€è¿‘ window å¤©çš„æ•°æ®
            y = series.iloc[-window:].values
            x = np.arange(len(y))
            
            slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)
            
            # R2 * Slopeç¬¦å·
            # æ˜¾å¼è½¬æ¢ç±»å‹ä»¥æ¶ˆé™¤ Pylance è­¦å‘Š
            r_sq = float(r_value) ** 2
            sign = 1.0 if float(slope) > 0 else -1.0
            
            trend_strength = r_sq * sign
            return trend_strength
        except Exception as e:
            # print(f"âš ï¸ RSRSè®¡ç®—å¼‚å¸¸: {e}")
            return 0.0

    def _calculate_rsrs_vectorized(self, price_matrix):
        """
        å‘é‡åŒ–è®¡ç®— RSRS
        Args:
            price_matrix: numpy array, shape (N_stocks, window_size)
        Returns:
            rsrs_values: numpy array, shape (N_stocks,)
        """
        if price_matrix.size == 0:
            return np.array([])

        N, T = price_matrix.shape

        # 1. å‡†å¤‡ X (æ—¶é—´åºåˆ— 0, 1, ..., T-1)
        x = np.arange(T)
        x_mean = x.mean()
        x_dev = x - x_mean             # Shape: (T,)
        x_var = np.sum(x_dev ** 2)     # Scalar (åˆ†æ¯éƒ¨åˆ†)

        # 2. å‡†å¤‡ Y (ä»·æ ¼åºåˆ—)
        y_mean = np.mean(price_matrix, axis=1, keepdims=True)
        y_dev = price_matrix - y_mean  # Shape: (N, T)

        # 3. è®¡ç®— Slope (æ–œç‡)
        # Cov(x, y) = sum(x_dev * y_dev)
        cov_xy = np.dot(y_dev, x_dev)  # Shape: (N,)
        slope = cov_xy / x_var

        # 4. è®¡ç®— R^2 (å†³å®šç³»æ•°)
        # R^2 = (Cov(x,y)^2) / (Var(x) * Var(y))
        y_var = np.sum(y_dev ** 2, axis=1) # Shape: (N,)

        # å¤„ç† y_var ä¸º 0 çš„æƒ…å†µ (ä»·æ ¼å®Œå…¨ä¸å˜)ï¼Œé¿å…é™¤é›¶é”™è¯¯
        valid_mask = y_var > 1e-10
        r_sq = np.zeros(N)

        # ä»…å¯¹æœ‰æ•ˆæ•°æ®è®¡ç®—
        r_sq[valid_mask] = (cov_xy[valid_mask] ** 2) / (x_var * y_var[valid_mask])

        # 5. è®¡ç®— RSRS = R^2 * Sign(Slope)
        rsrs = r_sq * np.sign(slope)

        return rsrs

    def test_rsrs_accuracy(self):
        """è‡ªæ£€å‡½æ•°ï¼šå¯¹æ¯”å‘é‡åŒ–ä¸Scipyçš„ç»“æœ"""
        print("ğŸ§ª æ­£åœ¨æ‰§è¡Œç®—æ³•ä¸€è‡´æ€§è‡ªæ£€...")
        # ç”Ÿæˆéšæœºæµ‹è¯•æ•°æ®
        np.random.seed(42)
        test_data = np.random.rand(100, 18) * 100  # 100åªè‚¡ç¥¨ï¼Œ18å¤©æ•°æ®

        # 1. å‘é‡åŒ–è®¡ç®—
        vec_res = self._calculate_rsrs_vectorized(test_data)

        # 2. å¾ªç¯è®¡ç®— (ä½¿ç”¨æ—§æ–¹æ³•)
        loop_res = []
        for row in test_data:
            loop_res.append(self.calculate_rsrs(pd.Series(row)))

        # 3. å¯¹æ¯”
        diff = np.abs(vec_res - np.array(loop_res))
        max_diff = diff.max()

        if max_diff < 1e-6:
            print("âœ… ç®—æ³•éªŒè¯é€šè¿‡ï¼è¯¯å·®æå°ã€‚")
        else:
            print(f"âŒ ç®—æ³•å­˜åœ¨å·®å¼‚ï¼Œæœ€å¤§è¯¯å·®: {max_diff}")
        return max_diff

    def get_connection(self, db_name):
        db_path = os.path.join(data_dir, db_name)
        if not os.path.exists(db_path):
            print(f"âŒ æ•°æ®åº“ä¸å­˜åœ¨: {db_path}")
            return None
        return sqlite3.connect(db_path)

    def analyze_market(self, market_type, db_name, amount_threshold):
        print(f"\nğŸš€ æ­£åœ¨åˆ†æ {market_type} å¸‚åœºåŠ¨é‡...")
        
        # 1. ä¼˜å…ˆä½¿ç”¨ä¼ å…¥å‚æ•°ï¼Œå¦åˆ™ä½¿ç”¨é…ç½®
        min_vol = amount_threshold  # ä¿ç•™åŸå‚æ•°ï¼Œä¸åšè¦†ç›–é€»è¾‘ï¼Œä»¥ä¿æŒå…¼å®¹
        blacklist = set(self.config.get('us_blacklist', []))
        window = self.config.get('rsrs_window', 18)
        max_change_pct = self.config.get('max_change_pct', 400)
        
        print(f"   âš™ï¸ ç­›é€‰æ ‡å‡†: 60æ—¥æ¶¨å¹…æ’å | 60æ—¥æ—¥å‡æˆäº¤é¢ > {min_vol/10000:.0f}ä¸‡")
        
        conn = self.get_connection(db_name)
        if not conn: return

        try:
            # è·å–æœ€æ–°æ—¥æœŸ
            cursor = conn.cursor()
            cursor.execute("SELECT MAX(date) FROM stock_prices")
            max_date = cursor.fetchone()[0]
            if not max_date:
                print("âš ï¸ æ•°æ®åº“ä¸ºç©º")
                return

            # åŠ è½½æœ€è¿‘åŠå¹´æ•°æ®
            print("â³ æ­£åœ¨åŠ è½½æ•°æ®åˆ°å†…å­˜...")
            query = f"""
                SELECT ticker, date, close, high, low, amount 
                FROM stock_prices 
                WHERE date >= date('{max_date}', '-180 days')
                ORDER BY ticker, date ASC
            """
            df = pd.read_sql_query(query, conn)
            
        except Exception as e:
            print(f"âŒ è¯»å–é”™è¯¯: {e}")
            return
        finally:
            conn.close()

        if df.empty:
            print("âš ï¸ æ— æ•°æ®")
            return

        print(f"ğŸ“Š æ•°æ®åŠ è½½å®Œæˆï¼Œå¼€å§‹ç­›é€‰ {len(df['ticker'].unique())} åªè‚¡ç¥¨...")
        
        # --- æ‰¹å¤„ç†å®¹å™¨ ---
        candidates_meta = []   # å­˜å‚¨å…ƒæ•°æ® (ticker, price, vol, etc.)
        candidates_prices = [] # å­˜å‚¨ä»·æ ¼åºåˆ— (ç”¨äºå‘é‡åŒ–è®¡ç®—)
        global_start_dates = []
        global_end_dates = []

        grouped = df.groupby('ticker')

        for ticker, group in grouped:
            if len(group) < 61: continue  # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®è®¡ç®— 60æ—¥æ¶¨å¹…
            
            # --- è¿‡æ»¤å™¨é€»è¾‘ (ä»é…ç½®è¯»å–) ---
            if market_type == 'US':
                if ticker in blacklist: continue
                # è¿‡æ»¤å¸¸è§çš„ warrant (æƒè¯) æˆ–å¼‚ç±»åç¼€ (5å­—ç¬¦ä»¥ä¸Šé€šå¸¸è¦æ³¨æ„)
                ticker_str = str(ticker)
                if len(ticker_str) > 4 and ticker_str not in ['GOOGL', 'BRK.B']: 
                    # ç®€å•å¯å‘å¼ï¼šç¾è‚¡æ­£è‚¡ä»£ç é€šå¸¸ <= 4 ä½ (é™¤äº†ä¸ªåˆ«)
                    # YieldMax å¾ˆå¤šæ˜¯ 4 ä½ï¼Œæ‰€ä»¥å¿…é¡»é  blacklist
                    pass

            if market_type == 'CN':
                # ç¡®ä¿ ticker æ˜¯å­—ç¬¦ä¸²
                ticker_str = str(ticker)
                raw_code = ticker_str.split('.')[0]
                if not raw_code.startswith(('00', '30', '60', '68')): continue
            
            # --- æµåŠ¨æ€§è¿‡æ»¤ ---
            avg_amt = group['amount'].tail(60).mean()
            if avg_amt < min_vol: continue

            # --- æ¶¨è·Œå¹…è®¡ç®— ---
            curr_row = group.iloc[-1]
            prev_row = group.iloc[-61]
            p_curr = curr_row['close']
            p_prev = prev_row['close']
            if p_prev == 0: continue
            
            change_pct = (p_curr - p_prev) / p_prev * 100
            
            # è™šå‡æš´æ¶¨ç†”æ–­è¿‡æ»¤
            if market_type == 'US' and change_pct > max_change_pct:
                continue
                
            # âœ… å…³é”®æ”¹åŠ¨: æ­¤æ—¶ä¸è®¡ç®— RSRSï¼Œåªæ”¶é›†æ•°æ®
            # è·å–æœ€è¿‘ window å¤©çš„æ”¶ç›˜ä»·
            recent_prices = group['close'].values[-window:]
            
            # å¦‚æœæ•°æ®ä¸è¶³ window å¤© (è™½ç„¶å‰é¢æ£€æŸ¥äº†61å¤©ï¼Œä½†ä»¥é˜²ä¸‡ä¸€)ï¼Œè¡¥0æˆ–è·³è¿‡
            if len(recent_prices) < window:
                continue

            candidates_prices.append(recent_prices)
            candidates_meta.append({
                'ticker': ticker,
                'price_60d_ago': round(p_prev, 2),
                'price_current': round(p_curr, 2),
                'change_percent': round(change_pct, 2),
                'avg_daily_volume': round(avg_amt, 0),
                'start_date': prev_row['date'],
                'end_date': curr_row['date']
            })
            
            global_start_dates.append(prev_row['date'])
            global_end_dates.append(curr_row['date'])

        # --- å‘é‡åŒ–è®¡ç®—é˜¶æ®µ ---
        if not candidates_meta:
            print("âš ï¸ æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„æ ‡çš„")
            return

        print(f"âš¡ æ­£åœ¨å¯¹ {len(candidates_meta)} åªä¼˜é€‰è‚¡ç¥¨è¿›è¡Œ RSRS å‘é‡åŒ–è®¡ç®—...")

        # è½¬æ¢ä¸º numpy çŸ©é˜µ (N, window)
        price_matrix = np.array(candidates_prices)

        # ğŸš€ ä¸€æ¬¡æ€§è®¡ç®—æ‰€æœ‰ RSRS
        rsrs_scores = self._calculate_rsrs_vectorized(price_matrix)

        # å°†ç»“æœåˆå¹¶å›å…ƒæ•°æ®
        for i, meta in enumerate(candidates_meta):
            meta['rsrs_z'] = round(rsrs_scores[i], 2)
            
        # --- åç»­è¾“å‡ºé€»è¾‘ ---
        results = pd.DataFrame(candidates_meta)
        results.sort_values('change_percent', ascending=False, inplace=True)
        top_200 = results.head(200)
        
        # æ–‡ä»¶åæ—¥æœŸé€»è¾‘ä¼˜åŒ–
        # End Date: å–æœ€å¤§å€¼ (æœ€æ–°æ—¥æœŸ)
        # Start Date: å–ä¼—æ•° (ç»å¤§å¤šæ•°è‚¡ç¥¨çš„èµ·å§‹æ—¥æœŸ)ï¼Œè¿‡æ»¤åœç‰Œè‚¡å¹²æ‰°
        if global_end_dates:
            file_end = max(global_end_dates).replace('-', '')
        else:
            file_end = datetime.now().strftime('%Y%m%d')
            
        if global_start_dates:
            # è·å–å‡ºç°æ¬¡æ•°æœ€å¤šçš„æ—¥æœŸ (Mode)
            most_common_start = Counter(global_start_dates).most_common(1)[0][0]
            file_start = most_common_start.replace('-', '')
        else:
            file_start = "00000000"
        
        filename = f"Top200_Momentum_{market_type}_{file_start}-{file_end}.csv"
        save_path = os.path.join(project_root, filename)
        
        output_cols = ['ticker', 'price_60d_ago', 'price_current', 'change_percent', 'avg_daily_volume', 'rsrs_z']
        top_200[output_cols].to_csv(save_path, index=False)
        
        print(f"âœ… {market_type} æ¦œå•å·²ç”Ÿæˆ: {filename}")
        print(f"   ğŸ¥‡ æ¦œé¦–: {top_200.iloc[0]['ticker']} (+{top_200.iloc[0]['change_percent']}%) | RSRS: {top_200.iloc[0]['rsrs_z']}")

def main():
    ranker = MomentumRanker()
    
    # Aè‚¡ (2äº¿ RMB)
    ranker.analyze_market('CN', 'market_data_cn.db', 200000000)
    
    # ç¾è‚¡ (2000ä¸‡ USD)
    ranker.analyze_market('US', 'market_data_us.db', 20000000)

if __name__ == "__main__":
    main()
