import sqlite3
import pandas as pd
import os
import sys
from datetime import datetime
from collections import Counter
from scipy import stats
import numpy as np

# è·¯å¾„è‡ªé€‚åº”
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
data_dir = os.path.join(project_root, 'data')

class MomentumRanker:
    def __init__(self):
        pass

    def calculate_rsrs_z(self, high_series, low_series, window=18):
        """
        è®¡ç®— RSRS æ ‡å‡†åˆ† (Z-Score)
        """
        if len(high_series) < window + 2:
            return 0.0
            
        high_vals = high_series.values
        low_vals = low_series.values
        
        # è®¡ç®—è¿‡å» 60 å¤©çš„ beta (å¦‚æœæ•°æ®è¶³å¤Ÿ)
        lookback = min(len(high_vals), 300)
        start_idx = len(high_vals) - lookback
        
        betas = []
        # è‡³å°‘éœ€è¦ window ä¸ªæ•°æ®ç‚¹æ‰èƒ½è®¡ç®—ä¸€ä¸ª beta
        if start_idx + window >= len(high_vals):
             # æ•°æ®å¤ªå°‘ï¼Œåªè®¡ç®—æœ€åä¸€ä¸ª
             start_idx = len(high_vals) - window - 1
             if start_idx < 0: return 0.0

        for i in range(start_idx + window, len(high_vals) + 1):
            y = high_vals[i-window:i]
            x = low_vals[i-window:i]
            # ç®€å•çš„çº¿æ€§å›å½’
            slope, _, _, _, _ = stats.linregress(x, y)
            betas.append(slope)
            
        if not betas:
            return 0.0
            
        betas_arr = np.array(betas)
        if len(betas_arr) < 10:
            # å†å²æ•°æ®ä¸è¶³ä»¥è®¡ç®— Z-Scoreï¼Œç›´æ¥è¿”å› 0 æˆ– beta æœ¬èº«
            return 0.0
            
        # Z-Score
        mean = np.mean(betas_arr)
        std = np.std(betas_arr)
        
        if std == 0:
            return 0.0
            
        current_beta = betas_arr[-1]
        z_score = (current_beta - mean) / std
        return z_score

    def get_connection(self, db_name):
        db_path = os.path.join(data_dir, db_name)
        if not os.path.exists(db_path):
            print(f"âŒ æ•°æ®åº“ä¸å­˜åœ¨: {db_path}")
            return None
        return sqlite3.connect(db_path)

    def analyze_market(self, market_type, db_name, amount_threshold):
        print(f"\nğŸš€ æ­£åœ¨åˆ†æ {market_type} å¸‚åœºåŠ¨é‡...")
        print(f"   âš™ï¸ ç­›é€‰æ ‡å‡†: 60æ—¥æ¶¨å¹…æ’å | 60æ—¥æ—¥å‡æˆäº¤é¢ > {amount_threshold/10000:.0f}ä¸‡")
        
        conn = self.get_connection(db_name)
        if not conn: return

        try:
            # 1. è·å–æœ€æ–°æ—¥æœŸ
            cursor = conn.cursor()
            cursor.execute("SELECT MAX(date) FROM stock_prices")
            max_date = cursor.fetchone()[0]
            if not max_date:
                print("âš ï¸ æ•°æ®åº“ä¸ºç©º")
                return

            # 2. åŠ è½½æœ€è¿‘åŠå¹´æ•°æ®
            print("â³ æ­£åœ¨åŠ è½½æ•°æ®åˆ°å†…å­˜...")
            # [MODIFIED] å¢åŠ  high, low ç”¨äºè®¡ç®— RSRS
            query = f"""
                SELECT ticker, date, close, high, low, amount 
                FROM stock_prices 
                WHERE date >= date('{max_date}', '-180 days')
                ORDER BY ticker, date ASC
            """
            df = pd.read_sql_query(query, conn)
            
        except Exception as e:
            print(f"âŒ è¯»å–é”™è¯¯: {e}")
            return
        finally:
            conn.close()

        if df.empty:
            print("âš ï¸ æ— æ•°æ®")
            return

        print(f"ğŸ“Š æ•°æ®åŠ è½½å®Œæˆï¼Œå¼€å§‹è®¡ç®— {len(df['ticker'].unique())} åªè‚¡ç¥¨...")
        
        results = []
        global_start_dates = []
        global_end_dates = []

        # 3. å‘é‡åŒ–/åˆ†ç»„è®¡ç®—
        grouped = df.groupby('ticker')
        
        # å®šä¹‰ç¾è‚¡é»‘åå• (åŒ…å«æ æ†ã€åå‘ã€æœŸæƒç­–ç•¥ ETF)
        us_blacklist = {
            # Leveraged/Inverse
            'SQQQ', 'TQQQ', 'SOXL', 'SOXS', 'SPXU', 'SPXS', 'SDS', 'SSO', 'UPRO', 
            'QID', 'QLD', 'TNA', 'TZA', 'UVXY', 'VIXY', 'SVXY', 'LABU', 'LABD', 
            'YANG', 'YINN', 'FNGU', 'FNGD', 'WEBL', 'WEBS', 'KOLD', 'BOIL',
            # YieldMax / Option Strategies (High Yield / Re-split frequent)
            'TSLY', 'NVDY', 'AMDY', 'MSTY', 'CONY', 'APLY', 'GOOY', 'MSFY', 'AMZY',
            'FBY', 'OARK', 'XOMO', 'JPMO', 'DISO', 'NFLY', 'SQY', 'PYPY', 'AIYY',
            'YMAX', 'YMAG', 'ULTY', 'SVOL', 'TLTW', 'HYGW', 'LQDW', 'BITX'
        }

        for ticker, group in grouped:
            if len(group) < 61: continue
            
            # --- 1. é»‘åå•è¿‡æ»¤ ---
            if market_type == 'US':
                if ticker in us_blacklist: continue
                # è¿‡æ»¤å¸¸è§çš„ warrant (æƒè¯) æˆ–å¼‚ç±»åç¼€ (5å­—ç¬¦ä»¥ä¸Šé€šå¸¸è¦æ³¨æ„)
                if len(ticker) > 4 and ticker not in ['GOOGL', 'BRK.B']: 
                    # ç®€å•å¯å‘å¼ï¼šç¾è‚¡æ­£è‚¡ä»£ç é€šå¸¸ <= 4 ä½ (é™¤äº†ä¸ªåˆ«)
                    # YieldMax å¾ˆå¤šæ˜¯ 4 ä½ï¼Œæ‰€ä»¥å¿…é¡»é  blacklist
                    pass

            # --- 2. Aè‚¡è¿‡æ»¤ ---
            if market_type == 'CN':
                # ç¡®ä¿ ticker æ˜¯å­—ç¬¦ä¸²
                ticker_str = str(ticker)
                raw_code = ticker_str.split('.')[0]
                if not raw_code.startswith(('00', '30', '60', '68')): continue
            
            # --- 3. æµåŠ¨æ€§è¿‡æ»¤ (60æ—¥å‡é¢) ---
            avg_amt = group['amount'].tail(60).mean()
            if avg_amt < amount_threshold: continue

            curr_row = group.iloc[-1]
            prev_row = group.iloc[-61]
            
            p_curr = curr_row['close']
            p_prev = prev_row['close']
            
            if p_prev == 0: continue
            
            change_pct = (p_curr - p_prev) / p_prev * 100
            
            # --- 4. è™šå‡æš´æ¶¨ç†”æ–­ (æ”¶ç´§è‡³ 400%) ---
            # è¿‡æ»¤æ‰å› åå‘æ‹†è‚¡ (Reverse Split) å¯¼è‡´çš„ä¸å¤æƒæ•°æ®æš´æ¶¨
            # ä»…å¯¹ç¾è‚¡åº”ç”¨æ­¤è¿‡æ»¤å™¨
            if market_type == 'US' and change_pct > 400: 
                continue

            # --- 5. [NEW] RSRS è®¡ç®— ---
            rsrs_z = 0.0
            if 'high' in group.columns and 'low' in group.columns:
                # ç®€å•çš„ç©ºå€¼æ£€æŸ¥
                if not group['high'].isnull().all() and not group['low'].isnull().all():
                    # å¡«å…… NaN ä»¥é˜²ä¸‡ä¸€ (ä½¿ç”¨ ffill() å’Œ bfill() æ›¿ä»£ method å‚æ•°)
                    h = group['high'].ffill().bfill()
                    l = group['low'].ffill().bfill()
                    rsrs_z = self.calculate_rsrs_z(h, l)
            
            results.append({
                'ticker': ticker,
                'price_60d_ago': round(p_prev, 2),
                'price_current': round(p_curr, 2),
                'change_percent': round(change_pct, 2),
                'avg_daily_volume': round(avg_amt, 0),
                'rsrs_z': round(rsrs_z, 2), # [NEW]
                'start_date': prev_row['date'],
                'end_date': curr_row['date']
            })
            
            global_start_dates.append(prev_row['date'])
            global_end_dates.append(curr_row['date'])

        # 4. æ±‡æ€»è¾“å‡º
        if not results:
            print("âš ï¸ æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„æ ‡çš„")
            return

        res_df = pd.DataFrame(results)
        res_df.sort_values('change_percent', ascending=False, inplace=True)
        top_200 = res_df.head(200)
        
        # 5. æ–‡ä»¶åæ—¥æœŸé€»è¾‘ä¼˜åŒ–
        # End Date: å–æœ€å¤§å€¼ (æœ€æ–°æ—¥æœŸ)
        # Start Date: å–ä¼—æ•° (ç»å¤§å¤šæ•°è‚¡ç¥¨çš„èµ·å§‹æ—¥æœŸ)ï¼Œè¿‡æ»¤åœç‰Œè‚¡å¹²æ‰°
        if global_end_dates:
            file_end = max(global_end_dates).replace('-', '')
        else:
            file_end = datetime.now().strftime('%Y%m%d')
            
        if global_start_dates:
            # è·å–å‡ºç°æ¬¡æ•°æœ€å¤šçš„æ—¥æœŸ (Mode)
            most_common_start = Counter(global_start_dates).most_common(1)[0][0]
            file_start = most_common_start.replace('-', '')
        else:
            file_start = "00000000"
        
        filename = f"Top200_Momentum_{market_type}_{file_start}-{file_end}.csv"
        save_path = os.path.join(project_root, filename)
        
        output_cols = ['ticker', 'price_60d_ago', 'price_current', 'change_percent', 'avg_daily_volume', 'rsrs_z']
        top_200[output_cols].to_csv(save_path, index=False)
        
        print(f"âœ… {market_type} æ¦œå•å·²ç”Ÿæˆ: {filename}")
        print(f"   ğŸ¥‡ æ¦œé¦–: {top_200.iloc[0]['ticker']} (+{top_200.iloc[0]['change_percent']}%) | RSRS: {top_200.iloc[0]['rsrs_z']}")

def main():
    ranker = MomentumRanker()
    
    # Aè‚¡ (1äº¿ RMB)
    ranker.analyze_market('CN', 'market_data_cn.db', 200000000)
    
    # ç¾è‚¡ (1000ä¸‡ USD)
    ranker.analyze_market('US', 'market_data_us.db', 20000000)

if __name__ == "__main__":
    main()
