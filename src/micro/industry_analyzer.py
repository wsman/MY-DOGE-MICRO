import os
import pandas as pd
import glob
from datetime import datetime
import sys
import yfinance as yf
import concurrent.futures # ç”¨äºå¹¶å‘åŠ é€Ÿè·å–ä¿¡æ¯

# --- è·¯å¾„ä¿®å¤ ---
current_dir = os.path.dirname(os.path.abspath(__file__)) # src/micro
src_dir = os.path.dirname(current_dir)                   # src
project_root = os.path.dirname(src_dir)                  # MY-DOGE-MICRO

if project_root not in sys.path:
    sys.path.insert(0, project_root)

# --- å¯¼å…¥ ---
try:
    from src.macro.config import MacroConfig
    from src.macro.strategist import DeepSeekStrategist
except ImportError as e:
    print(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")

# å¯¼å…¥æ•°æ®åº“ä¿å­˜å‡½æ•°
from database import save_research_report

class IndustryAnalyzer:
    def __init__(self, logger_callback=None):
        self.config = MacroConfig()
        self.strategist = DeepSeekStrategist(self.config)
        self.project_root = project_root
        self.logger_callback = logger_callback

    def load_latest_file(self, pattern):
        """åŠ è½½æœ€æ–°çš„æ–‡ä»¶"""
        files = glob.glob(pattern)
        if not files:
            return None
        return max(files, key=os.path.getctime)

    def log(self, message):
        """æ—¥å¿—è¾“å‡ºï¼šåŒæ—¶æ‰“å°åˆ°æ§åˆ¶å°å’Œå›è°ƒå‡½æ•°"""
        print(message)
        if self.logger_callback:
            self.logger_callback(message)

    def _process_csv(self, file_path, market_type):
        """å¤„ç† CSV æ–‡ä»¶å¹¶æ³¨å…¥å…ƒæ•°æ®ï¼ˆä¾›å¤–éƒ¨è°ƒç”¨ï¼‰"""
        df = pd.read_csv(file_path)
        # å–å‰ 50 åï¼Œé¿å… Token æº¢å‡ºï¼Œä¸”å¤´éƒ¨æ•ˆåº”æœ€æ˜æ˜¾
        top_50 = df.head(50) 
        
        self.log(f"ğŸ” æ­£åœ¨è”ç½‘æ ¡å‡† {market_type} å‰ 50 åè‚¡ç¥¨çš„ä¸šåŠ¡ä¿¡æ¯...")
        stock_list_str = []
        
        # å¹¶å‘è·å–ï¼Œé¿å…å¡é¡¿
        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
            future_to_ticker = {executor.submit(self.get_stock_metadata, row['ticker']): row for _, row in top_50.iterrows()}
            
            for future in concurrent.futures.as_completed(future_to_ticker):
                row = future_to_ticker[future]
                name, sector = future.result()
                
                # æ ¼å¼ï¼š- 605255.SH [Tianpu Stock] (Aerospace) | Change: +465%
                stock_list_str.append(
                    f"- {row['ticker']} [{name}] ({sector}) | æ¶¨å¹…: +{row['change_percent']}%"
                )
        
        return "\n".join(stock_list_str)

    def load_macro_context(self):
        """è¯»å–æœ€æ–°çš„å®è§‚æŠ¥å‘Šæ‘˜è¦"""
        # æ›´æ–°è·¯å¾„ä»¥åŒ…å« 'macro_report'
        report_dir = os.path.join(self.project_root, 'macro_report')
        latest_report = self.load_latest_file(os.path.join(report_dir, "*.md"))
        
        if not latest_report:
            return "N/A", "N/A", "No macro report found in macro_report/"
            
        with open(latest_report, 'r', encoding='utf-8') as f:
            content = f.read()
            
        # ç®€å•è§£æ Risk Signal å’Œ Volatility (å‡è®¾æ ¼å¼å›ºå®š)
        risk = "Risk-Off" if "Risk-Off" in content else "Risk-On"
        vol = "Unknown" # å¯ä»¥åŠ æ­£åˆ™æå– 17.xx%
        
        # æˆªå–å‰ 1000 å­—ä½œä¸ºæ‘˜è¦
        summary = content[:1000] 
        return risk, vol, summary

    def get_stock_metadata(self, ticker):
        """è·å–è‚¡ç¥¨åç§°å’Œè¡Œä¸šä¿¡æ¯ (æ¶ˆé™¤å¹»è§‰çš„å…³é”®)"""
        # 1. æ ¼å¼è½¬æ¢ (.SH -> .SS ç”¨äº yfinance)
        yf_ticker = ticker.replace(".SH", ".SS") if ".SH" in ticker else ticker
        
        try:
            info = yf.Ticker(yf_ticker).info
            # ä¼˜å…ˆå–ä¸­æ–‡åæˆ–ç®€ç§°ï¼ŒYahoo Aè‚¡é€šå¸¸æ˜¯è‹±æ–‡åï¼ŒAIèƒ½ç¿»è¯‘
            name = info.get('shortName', info.get('longName', 'Unknown'))
            sector = info.get('sector', info.get('industry', 'Unknown'))
            return name, sector
        except:
            return "Unknown", "Unknown"

    def load_momentum_data(self, market_type):
        """è¯»å– CSV å¹¶æ³¨å…¥å…ƒæ•°æ®"""
        # æ›´æ–°è·¯å¾„ä»¥åŒ…å« 'micro_report'
        csv_dir = os.path.join(self.project_root, 'micro_report')
        pattern = f"Top200_Momentum_{market_type}_*.csv"
        latest_csv = self.load_latest_file(os.path.join(csv_dir, pattern))
        
        if not latest_csv:
            print(f"âš ï¸ No CSV found for {market_type} in {csv_dir}")
            return "No data"
            
        df = pd.read_csv(latest_csv)
        # å–å‰ 50 åï¼Œé¿å… Token æº¢å‡ºï¼Œä¸”å¤´éƒ¨æ•ˆåº”æœ€æ˜æ˜¾
        top_50 = df.head(50) 
        
        print(f"ğŸ” æ­£åœ¨è”ç½‘æ ¡å‡† {market_type} å‰ 50 åè‚¡ç¥¨çš„ä¸šåŠ¡ä¿¡æ¯...")
        stock_list_str = []
        
        # å¹¶å‘è·å–ï¼Œé¿å…å¡é¡¿
        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
            future_to_ticker = {executor.submit(self.get_stock_metadata, row['ticker']): row for _, row in top_50.iterrows()}
            
            for future in concurrent.futures.as_completed(future_to_ticker):
                row = future_to_ticker[future]
                name, sector = future.result()
                
                # æ ¼å¼ï¼š- 605255.SH [Tianpu Stock] (Aerospace) | Change: +465%
                stock_list_str.append(
                    f"- {row['ticker']} [{name}] ({sector}) | æ¶¨å¹…: +{row['change_percent']}%"
                )
        
        return "\n".join(stock_list_str)

    def run_analysis(self, macro_path=None, cn_path=None, us_path=None):
        self.log("ğŸš€ å¯åŠ¨è¡Œä¸šè¶‹åŠ¿åˆ†æå¼•æ“...")
        
        # 1. å‡†å¤‡æ•°æ®
        if macro_path and os.path.exists(macro_path):
            with open(macro_path, 'r', encoding='utf-8') as f:
                content = f.read()
            risk = "Risk-Off" if "Risk-Off" in content else "Risk-On"
            vol = "Unknown"
            macro_summary = content[:1000]
        else:
            risk, vol, macro_summary = self.load_macro_context()
            
        # Micro CN & US
        if cn_path and os.path.exists(cn_path):
            cn_stocks = self._process_csv(cn_path, 'CN')
        else:
            cn_stocks = self.load_momentum_data('CN')

        if us_path and os.path.exists(us_path):
            us_stocks = self._process_csv(us_path, 'US')
        else:
            us_stocks = self.load_momentum_data('US')
        
        if cn_stocks == "No data" and us_stocks == "No data":
            self.log("âŒ ç¼ºå°‘åŠ¨é‡æ•°æ®ï¼Œæ— æ³•åˆ†æ")
            return None, None

        # 2. æ„å»º Prompt (æ–°å¢æœ€åä¸€æ®µ Metadata æŒ‡ä»¤)
        prompt = f"""
# Role
ä½ æ˜¯ä¸€ä½ç²¾é€šå…¨çƒäº§ä¸šé“¾çš„èµ„æ·±é‡åŒ–ç­–ç•¥åˆ†æå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºæˆ‘æä¾›çš„â€œå®è§‚ç¯å¢ƒâ€å’Œâ€œå¸‚åœºå¼ºåŠ¿è‚¡æ¸…å•â€ï¼Œé€šè¿‡å½’çº³æ³•æ¨å¯¼å‡ºå½“å‰å¤„äºâ€œæ™¯æ°”åº¦ä¸Šè¡ŒåŒºé—´â€çš„è¡Œä¸šæ¿å—ã€‚

# Input Data
## 1. Macro Context (å®è§‚èƒŒæ™¯)
- **Market Status**: {risk} (Risk-On / Risk-Off)
- **Volatility**: {vol}
- **Key Trend**: {macro_summary}

## 2. Micro Evidence (å¾®è§‚èµ„é‡‘æµå‘)
**[A-Share Top Momentum]**
{cn_stocks} 

**[US-Share Top Momentum]**
{us_stocks}

# Analysis Requirements
1.  **è¡Œä¸šæ˜ å°„**ï¼šè¯†åˆ«è‚¡ç¥¨ä»£ç å¯¹åº”çš„ç»†åˆ†èµ›é“ã€‚
2.  **é›†ç¾¤è¯†åˆ«**ï¼šæ‰¾å‡ºå‡ºç°é¢‘æ¬¡æœ€é«˜çš„ 3-5 ä¸ªç»†åˆ†è¡Œä¸šã€‚
3.  **å®è§‚éªŒè¯**ï¼šç»“åˆå®è§‚èƒŒæ™¯åˆ†æåˆç†æ€§ã€‚

# Output Format
è¯·ç”Ÿæˆä¸€ä»½ Markdown æ ¼å¼çš„ã€Šè¡Œä¸šæ™¯æ°”åº¦æ·±åº¦æ‰«ææŠ¥å‘Šã€‹ï¼ŒåŒ…å«ï¼š
1.  **æ ¸å¿ƒç»“è®º**
2.  **æ™¯æ°”åº¦æ’è¡Œ** (åˆ—å‡ºæœ€å¼ºè¡Œä¸š)
3.  **äº§ä¸šé“¾æ˜ å°„å›¾è°±** (å…±æŒ¯é€»è¾‘)
4.  **é£é™©æç¤º**

# ğŸ›‘ IMPORTANT: Metadata Output
åœ¨æŠ¥å‘Šçš„**æœ€åä¸€è¡Œ**ï¼Œè¯·åŠ¡å¿…æ ¹æ®æŠ¥å‘Šæ ¸å¿ƒç»“è®ºï¼Œç”Ÿæˆä¸€ä¸ªç®€çŸ­ã€ä¸“ä¸šçš„ä¸­æ–‡æ ‡é¢˜ï¼ˆ20å­—ä»¥å†…ï¼‰ï¼Œæ ¼å¼å¿…é¡»ä¸¥æ ¼å¦‚ä¸‹ï¼š
TITLE: [ä½ çš„æ ‡é¢˜]
(ä¾‹å¦‚: TITLE: é¿é™©æƒ…ç»ªä¸»å¯¼ï¼Œé»„é‡‘ä¸å†›å·¥æ¿å—æˆå…¨çƒå…±æŒ¯ä¸»çº¿)
"""
        
        # 3. è°ƒç”¨ API
        self.log("ğŸ§  æ­£åœ¨è°ƒç”¨ DeepSeek è¿›è¡Œäº§ä¸šé“¾èšç±»åˆ†æ...")
        try:
            response = self.strategist.client.chat.completions.create(
                model=self.config.model,
                messages=[
                    {"role": "system", "content": "You are a professional financial analyst."},
                    {"role": "user", "content": prompt}
                ],
                stream=False
            )
            
            raw_content = response.choices[0].message.content
            
            # --- æ ¸å¿ƒä¿®æ”¹ï¼šæå–è¯­ä¹‰åŒ–æ ‡é¢˜ ---
            import re
            title_match = re.search(r"TITLE:\s*(.*)", raw_content)
            
            if title_match:
                # æå–æ ‡é¢˜
                semantic_title = title_match.group(1).strip()
                # ä»æ­£æ–‡ä¸­ç§»é™¤ TITLE: è¡Œï¼Œä¿æŒæŠ¥å‘Šæ•´æ´
                report_content = raw_content.replace(title_match.group(0), "").strip()
            else:
                # Fallback: å¦‚æœæ²¡ç”Ÿæˆï¼Œä½¿ç”¨é»˜è®¤æ ¼å¼
                timestamp = datetime.now().strftime('%Y-%m-%d %H:%M')
                semantic_title = f"è¡Œä¸šå…¨æ™¯æ‰«æ ({timestamp})"
                report_content = raw_content

            # --- ä¿å­˜æ–‡ä»¶ (ä¿æŒæ—¶é—´æˆ³æ–‡ä»¶åï¼Œä¾¿äºæ’åº) ---
            model_name = self.config.model.replace("/", "-") if self.config.model else "unknown"
            timestamp_file = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')
            filename = f"report_by_{model_name}_{timestamp_file}.md"
            
            save_path = os.path.join(self.project_root, 'research_report', filename)
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            
            with open(save_path, 'w', encoding='utf-8') as f:
                f.write(report_content)
                
            self.log(f"âœ… è¡Œä¸šåˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {filename}")
            
            # --- å­˜å…¥æ•°æ®åº“ (ä½¿ç”¨è¯­ä¹‰åŒ–æ ‡é¢˜) ---
            self.log(f"ğŸ’¾ æ­£åœ¨è‡ªåŠ¨å½’æ¡£: ã€Š{semantic_title}ã€‹")
            
            current_analyst = self.config.model if self.config.model else "deepseek-chat"
            
            save_research_report(
                title=semantic_title,  # <--- è¿™é‡Œå­˜å…¥è¯­ä¹‰åŒ–æ ‡é¢˜
                content=report_content, 
                tags="Industry, DeepSeek",
                analyst=current_analyst
            )
            
            return report_content, filename
            
        except Exception as e:
            self.log(f"âŒ åˆ†æè¿‡ç¨‹å‡ºé”™: {e}")
            # æ‰“å°è¯¦ç»†å †æ ˆä»¥ä¾¿è°ƒè¯•
            import traceback
            traceback.print_exc()
            return None, None

if __name__ == "__main__":
    analyzer = IndustryAnalyzer()
    analyzer.run_analysis()
